{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os, re, sys\n",
    "sys.path.insert(0, '/home/paul/language-ident-from-speech/misc')\n",
    "from get_results import calculate_f_score\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_f1_data_normal(df):\n",
    "    f1_df = pd.DataFrame(columns=[\"expname\", \"f1_3s\", \"f1_10s\", \"f1_30s\"])\n",
    "    n = len(df)\n",
    "    langs = []\n",
    "    for i in range(n):\n",
    "        result_row = [df[\"expname\"].iloc[i]]\n",
    "        target_lang = df[\"excluded_languages\"].iloc[i]\n",
    "        langs.append(target_lang)\n",
    "        if target_lang == \"ALL\":\n",
    "            continue\n",
    "        for secs in [\"3s\", \"10s\", \"30s\"]:\n",
    "            col = \"classification_\" + secs\n",
    "            class_path = df[col][i]\n",
    "            if class_path != \"blank\":\n",
    "                prec, recall, f1 = calculate_f_score(class_path, target_lang, beta=1)\n",
    "                result_row.append(f1)\n",
    "            else:\n",
    "                result_row.append(\"none\")\n",
    "        f1_df.loc[i] = result_row\n",
    "    df = df.merge(f1_df, on=\"expname\", how=\"outer\")\n",
    "    return df, langs\n",
    "\n",
    "def add_f1_baseline(df, langs):\n",
    "    n = len(df)\n",
    "    rows_list = []\n",
    "    for i in range(n):\n",
    "        expname = [df[\"expname\"].iloc[i]][0]\n",
    "        for target_lang in langs:\n",
    "            result_row = [expname, target_lang]\n",
    "            for secs in [\"3s\", \"10s\", \"30s\"]:\n",
    "                col = \"classification_\" + secs\n",
    "                class_path = df[col][i]\n",
    "                if class_path != \"blank\":\n",
    "                    prec, recall, f1 = calculate_f_score(class_path, target_lang, beta=1)\n",
    "                    result_row.append(f1)\n",
    "                else:\n",
    "                    result_row.append(\"none\")\n",
    "            rows_list.append(result_row)\n",
    "    f1_df = pd.DataFrame(rows_list, columns=[\"expname\", \"excluded_languages\", \"f1_3s\", \"f1_10s\", \"f1_30s\"])\n",
    "    #df = df.merge(f1_df, on=\"expname\", how=\"outer\")\n",
    "    return f1_df\n",
    "\n",
    "def generate_col_names():\n",
    "    names = []\n",
    "    for stat in [\"mean\", \"std\"]:\n",
    "        for i in [\"3\", \"10\", \"30\"]:\n",
    "            names.append(stat + \"_f1_\" + i + \"s\")\n",
    "    return names\n",
    "\n",
    "def average_baseline_df(df):\n",
    "    df.sort_values(\"excluded_languages\", inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    numeric_cols = [\"f1_3s\", \"f1_10s\", \"f1_30s\"]\n",
    "    cols = [\"excluded_language\"] + generate_col_names()\n",
    "    rows = []\n",
    "    n = len(df)\n",
    "    for i in np.arange(0, n, step=3):\n",
    "        lang = df[\"excluded_languages\"][i]\n",
    "        if (lang != df[\"excluded_languages\"][i+1] and \n",
    "            lang != df[\"excluded_languages\"][i+2]):\n",
    "            print(\"Warning: the three languages are not the same\")\n",
    "            continue\n",
    "        mean = df.loc[[i, i+1, i+2]][numeric_cols].mean()\n",
    "        std = df.loc[[i, i+1, i+2]][numeric_cols].std()\n",
    "        rows.append([lang] + list(mean) + list(std))\n",
    "    avg_df = pd.DataFrame(rows, columns=cols)\n",
    "    return avg_df\n",
    "\n",
    "def average_df(df):\n",
    "    exp_list = get_expname_and_number(list(df[\"expname\"]))\n",
    "    cols = [\"excluded_language\"] + generate_col_names()\n",
    "    rows = []\n",
    "    for i, exps in enumerate(exp_list):\n",
    "        excluded_lang = get_lang(expname)\n",
    "         for exp in exps:\n",
    "            \n",
    "            df_results[\"mean_\" + category].loc[i] = mean\n",
    "            df_results[\"std_\" + category].loc[i] = std\n",
    "    df_results = df_results.sort_values(\"enroll_length\")\n",
    "    df_results = df_results.sort_values(\"train_length\")\n",
    "    df_results = df_results.reset_index(drop=True)\n",
    "    return df_results\n",
    "\n",
    "def get_lang(expname):\n",
    "    \n",
    "\n",
    "def get_expname_and_number(expnames):\n",
    "    exp_list = []\n",
    "    found_names = []\n",
    "    counts = []\n",
    "    for exp in expnames:\n",
    "        if exp[-2] == \"_\":\n",
    "            name = exp[:-2]\n",
    "        else:\n",
    "            name = exp\n",
    "        if name not in found_names:\n",
    "            found_names.append(name)\n",
    "            counts.append(1)\n",
    "        else:\n",
    "            idx = found_names.index(name)\n",
    "            counts[idx] += 1\n",
    "    for idx, name in enumerate(found_names):\n",
    "        count = counts[idx]\n",
    "        name_list = [name]\n",
    "        if count > 1:\n",
    "            for i in range(2, count + 1):\n",
    "                new_name = name + \"_\" + str(i)\n",
    "                name_list.append(new_name)\n",
    "        exp_list.append(name_list)\n",
    "    return exp_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/miniconda3/envs/lid/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "ad_summary = pd.read_csv(join(os.getcwd(), \"results\", \"ad_all_summary.csv\"))\n",
    "baseline = ad_summary[ad_summary.excluded_languages == \"ALL\"]\n",
    "baseline.reset_index(drop=True, inplace=True)\n",
    "baseline.drop(\"excluded_languages\", axis=1, inplace=True)\n",
    "ad_normal = ad_summary[ad_summary.excluded_languages != \"ALL\"]\n",
    "ad_normal.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ad_normal, langs = add_f1_data_normal(ad_normal)\n",
    "baseline_new = add_f1_baseline(baseline, langs)\n",
    "avg_baseline = average_ad_df(baseline_new,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_list = get_expname_and_number(ad_normal[\"expname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ad_all_tr_no_ar'],\n",
       " ['ad_all_tr_no_bg'],\n",
       " ['ad_all_tr_no_ch'],\n",
       " ['ad_all_tr_no_cr'],\n",
       " ['ad_all_tr_no_cz'],\n",
       " ['ad_all_tr_no_fr'],\n",
       " ['ad_all_tr_no_ge'],\n",
       " ['ad_all_tr_no_ja'],\n",
       " ['ad_all_tr_no_ko'],\n",
       " ['ad_all_tr_no_pl'],\n",
       " ['ad_all_tr_no_po'],\n",
       " ['ad_all_tr_no_ru'],\n",
       " ['ad_all_tr_no_sp'],\n",
       " ['ad_all_tr_no_sw'],\n",
       " ['ad_all_tr_no_th'],\n",
       " ['ad_all_tr_no_tu'],\n",
       " ['ad_all_tr_no_vn'],\n",
       " ['ad_all_tr_no_wu']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
