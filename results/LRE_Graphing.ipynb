{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from os.path import join, exists\n",
    "from scipy.interpolate import make_interp_spline, BSpline\n",
    "root_data_dir = join(\"/home\", \"paul\", \"gp-data\")\n",
    "home_dir = join(\"/home\", \"paul\", \"language-ident-from-speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     27,
     34,
     46,
     53,
     78,
     81,
     90,
     102,
     140,
     184,
     199,
     206,
     230,
     237,
     246,
     270
    ]
   },
   "outputs": [],
   "source": [
    "def average_df(df):\n",
    "    exp_list = get_expname_and_number(list(df[\"expname\"]))\n",
    "    categories = [\"accuracy_3s\", \"accuracy_10s\", \"accuracy_30s\",\n",
    "                     \"c_primary_3s\", \"c_primary_10s\", \"c_primary_30s\"]\n",
    "    avg_categories = get_mean_std_category_list(categories)\n",
    "    df_results = pd.DataFrame(columns=[\"expname\", \"train_length\", \"enroll_length\"] + avg_categories)\n",
    "    for i, exps in enumerate(exp_list):\n",
    "        expname = exps[0]\n",
    "        tr_length, en_length = get_lengths_from_expname(expname)\n",
    "        df_results.loc[i] = [expname, tr_length, en_length, -1, -1, -1, -1, -1, -1, \n",
    "                             -1, -1, -1, -1, -1, -1]\n",
    "        for category in categories:\n",
    "            indices = []\n",
    "            for exp in exps:\n",
    "                idx = df[df[\"expname\"] == exp].index[0]\n",
    "                indices.append(idx)\n",
    "            vals = list(df[category].loc[indices])\n",
    "            vals = list(extract_nums(vals))\n",
    "            mean = np.mean(vals)\n",
    "            std = np.std(vals)\n",
    "            df_results[\"mean_\" + category].loc[i] = mean\n",
    "            df_results[\"std_\" + category].loc[i] = std\n",
    "    df_results = df_results.sort_values(\"enroll_length\")\n",
    "    df_results = df_results.sort_values(\"train_length\")\n",
    "    df_results = df_results.reset_index(drop=True)\n",
    "    return df_results\n",
    "            \n",
    "def extract_nums(vals):\n",
    "    for item in vals:\n",
    "        try:\n",
    "            yield float(item)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        \n",
    "def get_lengths_from_expname(expname):\n",
    "    if \"baseline\" in expname:\n",
    "        return \"all\", \"all\"\n",
    "    if expname[-2] == \"_\":\n",
    "        string = expname[:-2]\n",
    "    else:\n",
    "        string = expname\n",
    "    entry = string.split(\"_\")\n",
    "    tr_length = int(entry[2])\n",
    "    en_length = int(entry[4])\n",
    "    return tr_length, en_length\n",
    "        \n",
    "def get_mean_std_category_list(categories):\n",
    "    list_out = []\n",
    "    for cat in categories:\n",
    "        list_out.append(\"mean_\" + cat)\n",
    "        list_out.append(\"std_\" + cat)\n",
    "    return list_out\n",
    "    \n",
    "def get_expname_and_number(expnames):\n",
    "    exp_list = []\n",
    "    found_names = []\n",
    "    counts = []\n",
    "    for exp in expnames:\n",
    "        if exp[-2] == \"_\":\n",
    "            name = exp[:-2]\n",
    "        else:\n",
    "            name = exp\n",
    "        if name not in found_names:\n",
    "            found_names.append(name)\n",
    "            counts.append(1)\n",
    "        else:\n",
    "            idx = found_names.index(name)\n",
    "            counts[idx] += 1\n",
    "    for idx, name in enumerate(found_names):\n",
    "        count = counts[idx]\n",
    "        name_list = [name]\n",
    "        if count > 1:\n",
    "            for i in range(2, count + 1):\n",
    "                new_name = name + \"_\" + str(i)\n",
    "                name_list.append(new_name)\n",
    "        exp_list.append(name_list)\n",
    "    return exp_list\n",
    "\n",
    "def get_mean_info_str(category, seconds):\n",
    "    return \"mean_\" + category + \"_\" + str(seconds) + \"s\"\n",
    "\n",
    "def get_square_df(df, category, seconds):\n",
    "    mean_cols = [\"train_length\", \"enroll_length\", \n",
    "                get_mean_info_str(category, seconds)]\n",
    "    mean_df = df[mean_cols]\n",
    "    mean_df = mean_df.pivot(index=\"train_length\", \n",
    "                            columns=\"enroll_length\")\n",
    "    mean_df = mean_df.sort_index(ascending=False)\n",
    "    return mean_df\n",
    "\n",
    "def find_min_max(dfs):\n",
    "    min_val = 99999\n",
    "    max_val = -1\n",
    "    for df in dfs:\n",
    "        min_df = min(df.min())\n",
    "        if min_df < min_val:\n",
    "            min_val = min_df\n",
    "        max_df = max(df.max())\n",
    "        if max_df > max_val:\n",
    "            max_val = max_df\n",
    "    return min_val, max_val\n",
    "\n",
    "def plot_lre_heatmap(df, category, seconds, savename=None, cmap=\"magma\", \n",
    "                     precision='.3f', size=(5,4)):\n",
    "    if category not in [\"accuracy\", \"c_primary\"]:\n",
    "        print(\"Invalid category given: {}\" + \n",
    "              \"\\nShould be \\\"accuracy\\\" or \\\"c_primary\\\"\"\n",
    "              .format(category))\n",
    "        return\n",
    "    if seconds not in [3, 10, 30]:\n",
    "        print(\"Invalid seconds length given: {}\" +\n",
    "              \"\\nShould be an integer of 3, 10 or 30\".format(seconds))\n",
    "        return\n",
    "    mean_info = get_mean_info_str(category, seconds)\n",
    "    std_info = \"std_\" + category + \"_\" + str(seconds) + \"s\"\n",
    "    \n",
    "    # Reverse colours if c_primary to look similar to accs\n",
    "    if category == \"c_primary\":\n",
    "        cmap=cmap + \"_r\"\n",
    "    \n",
    "    mean_cols = [\"train_length\", \"enroll_length\", mean_info]\n",
    "    std_cols = [\"train_length\", \"enroll_length\", std_info]\n",
    "    mean_df = df[mean_cols]\n",
    "    std_df = df[std_cols]\n",
    "    \n",
    "    mean_df = mean_df.pivot(index=\"train_length\", \n",
    "                            columns=\"enroll_length\")\n",
    "    mean_df = mean_df.sort_index(ascending=False)\n",
    "    plt.figure(figsize=size)\n",
    "    sns.set(font_scale=1.1)\n",
    "    sns.heatmap(mean_df, annot=True, cmap=cmap, fmt=precision)\n",
    "    tick_pos = [0.5, 1.5, 2.5, 3.5]\n",
    "    plt.xlabel(\"Enrollment data (s)\")\n",
    "    plt.xticks(tick_pos, labels=[\"500\", \"1000\", \"5000\", \"10000\"], \n",
    "               rotation=0)\n",
    "    plt.ylabel(\"Training data (s)\")\n",
    "    plt.tight_layout()\n",
    "    if savename is not None:\n",
    "        plt.savefig(savename + \".pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "def plot_multiple_heatmaps(df, category, savename=None, cmap=\"magma\", \n",
    "                           precision='.3f', size=(12,4), compare=True):\n",
    "    mean_df_3 = get_square_df(df, category, 3)\n",
    "    mean_df_10 = get_square_df(df, category, 10)\n",
    "    mean_df_30 = get_square_df(df, category, 30)\n",
    "    if compare:\n",
    "        vmin,vmax = find_min_max([mean_df_3, mean_df_10, mean_df_30])\n",
    "    else:\n",
    "        vmin = None\n",
    "        vmax = None\n",
    "    # Reverse colours if c_primary to look similar to accs\n",
    "    if category == \"c_primary\":\n",
    "        cmap=cmap + \"_r\"\n",
    "    \n",
    "    f,(ax1, ax2, ax3, axcb) = plt.subplots(1, 4,\n",
    "                              gridspec_kw={\"width_ratios\": [1,1,1,0.08]},\n",
    "                              figsize=size)\n",
    "    ax1.get_shared_y_axes().join(ax2, ax3)\n",
    "    sns.set(font_scale=1)\n",
    "    g1 = sns.heatmap(mean_df_3, cmap=cmap, annot=True, fmt=precision,\n",
    "                     cbar=False, ax=ax1, vmin=vmin, vmax=vmax)\n",
    "    g1.set_ylabel(\"Training data (s)\")\n",
    "    g1.set_xlabel(\"\")\n",
    "    g1.set_title(\"3s evaluation\")\n",
    "    g2 = sns.heatmap(mean_df_10, cmap=cmap, annot=True, fmt=precision,\n",
    "                     cbar=False, ax=ax2, vmin=vmin, vmax=vmax)\n",
    "    g2.set_ylabel(\"\")\n",
    "    g2.set_xlabel(\"Enrollment data (s)\")\n",
    "    g2.set_title(\"10s evaluation\")\n",
    "    g2.set_yticks([])\n",
    "    g3 = sns.heatmap(mean_df_30, cmap=cmap, annot=True, fmt=precision,\n",
    "                     ax=ax3, cbar_ax=axcb, vmin=vmin, vmax=vmax)\n",
    "    g3.set_ylabel(\"\")\n",
    "    g3.set_xlabel(\"\")\n",
    "    g3.set_title(\"30s evaluation\")\n",
    "    g3.set_yticks([])\n",
    "    for ax in [g1,g2,g3]:\n",
    "        labels = [\"500\", \"1000\", \"5000\", \"10000\"]\n",
    "        ax.set_xticklabels(labels,rotation=0)\n",
    "        \n",
    "    if savename is not None:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savename + \".pdf\", bbox_inches=\"tight\")\n",
    "        \n",
    "def get_nnet_df(expname):\n",
    "    exp_path = join(root_data_dir, expname, \n",
    "                    \"nnet\", \"accuracy.output.report\")\n",
    "    if not exists(exp_path):\n",
    "        print(\"Path not found at {}\".format(exp_path))\n",
    "        return None\n",
    "    nnet_df = pd.read_csv(exp_path, delim_whitespace=True)\n",
    "    nnet_df.drop(nnet_df.tail(1).index,inplace=True)\n",
    "    nnet_df.drop([\"duration\", \"difference\"],axis=1, inplace=True)\n",
    "    nnet_df = nnet_df.apply(pd.to_numeric)\n",
    "    nnet_df.rename(columns={\"%Iter\":\"iteration\",\n",
    "                            \"train_objective\": \"train_acc\",\n",
    "                            \"valid_objective\": \"valid_acc\"},inplace=True)\n",
    "    return nnet_df\n",
    "\n",
    "def get_col_names(category, length):\n",
    "    acc = category + \"_acc\"\n",
    "    if length == 3:\n",
    "        return [acc, acc + \"_x\", acc + \"_y\"]\n",
    "    else:\n",
    "        return [acc]\n",
    "\n",
    "def get_average_nnet_df(exps):\n",
    "    all_dfs = []\n",
    "    for exp in exps:\n",
    "        all_dfs.append(get_nnet_df(exp))\n",
    "    full_df = all_dfs[0]\n",
    "    if len(all_dfs) > 1:\n",
    "        for df in all_dfs[1:]:\n",
    "            full_df = pd.merge(full_df, df, on=\"iteration\", how=\"inner\")\n",
    "    for category in [\"train\", \"valid\"]:\n",
    "        cols = get_col_names(category, len(exps))\n",
    "        full_df[\"mean_\" + category + \"_acc\"] = full_df[cols].mean(axis=1)\n",
    "        full_df[\"min_\" + category + \"_acc\"] = full_df[cols].min(axis=1)\n",
    "        full_df[\"max_\" + category + \"_acc\"] = full_df[cols].max(axis=1)\n",
    "        if len(all_dfs) > 1:\n",
    "            full_df[\"std_\" + category + \"_acc\"] = full_df[cols].std(axis=1)\n",
    "        else:\n",
    "            full_df[\"std_\" + category + \"_acc\"] = float(0)\n",
    "        full_df.drop(cols, axis=1, inplace=True)\n",
    "    full_df[\"iteration\"] += 1\n",
    "    full_df.loc[-1] = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    full_df.index = full_df.index + 1\n",
    "    full_df.sort_index(inplace=True)\n",
    "    return full_df\n",
    "\n",
    "def get_vals(exp_df, category):\n",
    "    mean_vals = exp_df[\"mean_\" + category + \"_acc\"]\n",
    "    std_vals = exp_df[\"std_\" + category + \"_acc\"]\n",
    "    max_vals = exp_df[\"max_\" + category + \"_acc\"]\n",
    "    min_vals = exp_df[\"min_\" + category + \"_acc\"]\n",
    "    return mean_vals, std_vals, max_vals, min_vals\n",
    "\n",
    "def get_ylabel(category):\n",
    "    if category == \"valid\":\n",
    "        return \"Mean validation accuracy (%)\"\n",
    "    elif category == \"train\":\n",
    "        return \"Mean training accuracy (%)\"\n",
    "    else:\n",
    "        print(\"Unknown category: {}\".format(category))\n",
    "        return category\n",
    "\n",
    "def get_all_nnet_dfs(lre_df, baseline_df):\n",
    "    exp_list = get_expname_and_number(list(lre_df[\"expname\"]))\n",
    "    baseline_list = get_expname_and_number(list(baseline_df[\"expname\"]))\n",
    "    for idx, exps in enumerate(exp_list):\n",
    "        #print(exps)\n",
    "        exp = exps[0]\n",
    "        if \"en_500\" in exp and not \"en_5000\" in exp:\n",
    "            if \"tr_10000\" in exp:\n",
    "                nnet_10000_df = get_average_nnet_df(exps)\n",
    "                nnet_10000_df.name = \"10000\"\n",
    "            elif \"tr_5000\" in exp:\n",
    "                nnet_5000_df = get_average_nnet_df(exps)\n",
    "                nnet_5000_df.name = \"5000\"\n",
    "            elif \"tr_1000\" in exp:\n",
    "                nnet_1000_df = get_average_nnet_df(exps)\n",
    "                nnet_1000_df.name = \"1000\"\n",
    "            elif \"tr_500\" in exp:\n",
    "                nnet_500_df = get_average_nnet_df(exps)\n",
    "                nnet_500_df.name = \"500\"\n",
    "    for exps in baseline_list:\n",
    "        baseline_df = get_average_nnet_df(exps)\n",
    "        baseline_df.name = \"Baseline\"\n",
    "    return [baseline_df, nnet_500_df, nnet_1000_df, nnet_5000_df, nnet_10000_df]\n",
    "        \n",
    "def plot_multiple_exp_line(exp_dfs, category, legend_loc=\"best\", size=(10,6), show_err=True,\n",
    "                      alpha=0.1, ylim=None, xlim=None, savename=None, smooth=False):\n",
    "    colours = sns.color_palette()\n",
    "    max_colours = len(colours)\n",
    "    max_iterations = 0\n",
    "    plt.figure(figsize=size)\n",
    "    for idx, exp_df in enumerate(exp_dfs):\n",
    "        iterations = exp_df[\"iteration\"]\n",
    "        if len(iterations) + 1 > max_iterations:\n",
    "            max_iterations = len(iterations) + 1\n",
    "        exp_label=exp_df.name\n",
    "        mean_vals, std_vals, _, _ = get_vals(exp_df, category)\n",
    "        colour_idx = idx % max_colours\n",
    "        if not smooth:\n",
    "            plt.plot(iterations, mean_vals, '-', color=colours[colour_idx], label=exp_label)\n",
    "        else:\n",
    "            xnew = np.linspace(0, iterations.max(), 100)\n",
    "            spl = make_interp_spline(iterations, mean_vals, k=3)\n",
    "            power_smooth = spl(xnew)\n",
    "            plt.plot(xnew, power_smooth, '-', color=colours[colour_idx], label=exp_label)\n",
    "        if show_err:\n",
    "            plt.fill_between(iterations, mean_vals - std_vals, mean_vals + std_vals,\n",
    "                            color=colours[colour_idx], alpha=alpha)\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor(\"w\")\n",
    "    ax.spines['bottom'].set_color(\"black\")\n",
    "    ax.spines['left'].set_color(\"black\")\n",
    "    ax.set_ylabel(get_ylabel(category))\n",
    "    ax.set_xlabel(\"Iterations\")\n",
    "    if xlim is not None:\n",
    "        ax.set_xlim(xlim)\n",
    "    else:\n",
    "        ax.set_xlim(0, max_iterations)\n",
    "    if ylim is not None:\n",
    "        ax.set_ylim(ylim)\n",
    "    else:\n",
    "        ax.set_ylim(bottom=0)\n",
    "    plt.legend(loc=legend_loc, title=\"Training data (s)\", facecolor=\"w\")\n",
    "    plt.tight_layout()\n",
    "    if savename is not None:\n",
    "        plt.savefig(savename + \".pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expname</th>\n",
       "      <th>training_length</th>\n",
       "      <th>enrollment_length</th>\n",
       "      <th>seed</th>\n",
       "      <th>classification_3s</th>\n",
       "      <th>classification_10s</th>\n",
       "      <th>classification_30s</th>\n",
       "      <th>accuracy_3s</th>\n",
       "      <th>accuracy_10s</th>\n",
       "      <th>accuracy_30s</th>\n",
       "      <th>c_primary_3s</th>\n",
       "      <th>c_primary_10s</th>\n",
       "      <th>c_primary_30s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>lre_baseline</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>1</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline/exp/results/cl...</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline/exp/results/cl...</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline/exp/results/cl...</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lre_baseline_2</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>2</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline_2/exp/results/...</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline_2/exp/results/...</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline_2/exp/results/...</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lre_baseline_3</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>3</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>/home/paul/gp-data/lre_baseline_3/exp/results/...</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.873</td>\n",
       "      <td>blank</td>\n",
       "      <td>blank</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           expname training_length enrollment_length  seed  \\\n",
       "16    lre_baseline             all               all     1   \n",
       "27  lre_baseline_2             all               all     2   \n",
       "39  lre_baseline_3             all               all     3   \n",
       "\n",
       "                                    classification_3s  \\\n",
       "16  /home/paul/gp-data/lre_baseline/exp/results/cl...   \n",
       "27  /home/paul/gp-data/lre_baseline_2/exp/results/...   \n",
       "39                                              blank   \n",
       "\n",
       "                                   classification_10s  \\\n",
       "16  /home/paul/gp-data/lre_baseline/exp/results/cl...   \n",
       "27  /home/paul/gp-data/lre_baseline_2/exp/results/...   \n",
       "39                                              blank   \n",
       "\n",
       "                                   classification_30s accuracy_3s  \\\n",
       "16  /home/paul/gp-data/lre_baseline/exp/results/cl...       0.741   \n",
       "27  /home/paul/gp-data/lre_baseline_2/exp/results/...       0.741   \n",
       "39  /home/paul/gp-data/lre_baseline_3/exp/results/...       blank   \n",
       "\n",
       "   accuracy_10s  accuracy_30s c_primary_3s c_primary_10s  c_primary_30s  \n",
       "16        0.852         0.873        0.344         0.204          0.189  \n",
       "27        0.852         0.873        0.344         0.204          0.189  \n",
       "39        blank         0.873        blank         blank          0.189  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(join(home_dir, \"results\", \"lre_summary.csv\"))\n",
    "\n",
    "# Filter expts from baseline\n",
    "baseline_df = all_df[all_df.training_length == \"all\"]\n",
    "lre_df = all_df[all_df.training_length != \"all\"]\n",
    "\n",
    "avg_baseline = average_df(baseline_df)\n",
    "avg_lre = average_df(lre_df)\n",
    "avg_lre = avg_lre.drop(\"expname\", axis=1)\n",
    "avg_lre = avg_lre.apply(pd.to_numeric)\n",
    "\n",
    "#plot_lre_heatmap(avg_lre, \"c_primary\", 30, cmap=\"magma\")\n",
    "#plot_multiple_heatmaps(avg_lre, \"accuracy\", savename=\"all_lre_accs\")\n",
    "#plot_multiple_heatmaps(avg_lre, \"c_primary\", savename=\"all_lre_c_primary\")\n",
    "\n",
    "exp_dfs = get_all_nnet_dfs(lre_df, baseline_df)\n",
    "\n",
    "#plot_multiple_exp_line(exp_dfs, \"valid\", smooth=True, savename=\"lre_valid_nnet_smooth\")  \n",
    "#plot_multiple_exp_line(exp_dfs, \"valid\", smooth=False, savename=\"lre_valid_nnet_rough\")\n",
    "#plot_multiple_exp_line(exp_dfs, \"train\", smooth=True, savename=\"lre_train_nnet_smooth\")\n",
    "#plot_multiple_exp_line(exp_dfs, \"train\", smooth=False, savename=\"lre_train_nnet_rough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expname</th>\n",
       "      <th>train_length</th>\n",
       "      <th>enroll_length</th>\n",
       "      <th>mean_accuracy_3s</th>\n",
       "      <th>std_accuracy_3s</th>\n",
       "      <th>mean_accuracy_10s</th>\n",
       "      <th>std_accuracy_10s</th>\n",
       "      <th>mean_accuracy_30s</th>\n",
       "      <th>std_accuracy_30s</th>\n",
       "      <th>mean_c_primary_3s</th>\n",
       "      <th>std_c_primary_3s</th>\n",
       "      <th>mean_c_primary_10s</th>\n",
       "      <th>std_c_primary_10s</th>\n",
       "      <th>mean_c_primary_30s</th>\n",
       "      <th>std_c_primary_30s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lre_baseline</td>\n",
       "      <td>all</td>\n",
       "      <td>all</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0</td>\n",
       "      <td>0.873</td>\n",
       "      <td>1.11022e-16</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        expname train_length enroll_length mean_accuracy_3s  std_accuracy_3s  \\\n",
       "0  lre_baseline          all           all            0.741                0   \n",
       "\n",
       "  mean_accuracy_10s  std_accuracy_10s mean_accuracy_30s std_accuracy_30s  \\\n",
       "0             0.852                 0             0.873      1.11022e-16   \n",
       "\n",
       "  mean_c_primary_3s  std_c_primary_3s mean_c_primary_10s  std_c_primary_10s  \\\n",
       "0             0.344                 0              0.204                  0   \n",
       "\n",
       "  mean_c_primary_30s  std_c_primary_30s  \n",
       "0              0.189                  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
